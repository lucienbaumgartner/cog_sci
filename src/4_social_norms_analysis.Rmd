---
title: 'Cognition Paper: Ex. 4 Social Norms'
date: "9/24/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=80), tidy=TRUE)
```

## Hypotheses

- H1: It is **more acceptable** to use **positive thick terms** without intending to communicate the evaluation they usually (based on intuition and sentiment analysis) convey, **than** it is to use **negative thick terms** without intending to communicate the evaluation they usually convey.
    - $y = \text{Social Norm}, H_A:\mu_{pos}<\mu_{neg}$, for the one-sided t-test
    - **CANNOT BE REJECTED**
- H2: It is **more problematic** to get a wrong impression of a person if the impression is **wrongly negative**, **compared to** when it is **wrongly positive**.
    - $y = \text{Problem}, H_A:\mu_{pos}<\mu_{neg}$, for the one-sided t-test
    - **CANNOT BE REJECTED**
    
Since there could be order effects, we first tested each of the hypotheses on the first item only. In a second step, we tested for order effects in the collapsed model (both item of each participant). Since in both cases the order effects were not significant on .05-alpha level, we can use the pooled data for hypothesis testing.

## H1: Social Norms

**The ANOVA-assumptions are partially met.** The more important of both assumptions, homogeneity of variance, cannot be rejected. This means **we can use standard parametric methods** (i.e. ANOVA, and one-sided t-tests) to test the hypothesis. The first result of each test is for the pooled data (`h1`), the second for the first item subset (`h1_V1`).

```{r echo=FALSE, message=F, include=F}
library(dplyr)
library(reshape2)
library(stringr)
library(quanteda)
library(lawstat)
library(emmeans)
rm(list=ls())

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()

# load data
load('../output/data/4-social-norms.RDS')


### H1
# It is more acceptable to use positive thick terms without intending to communicate the evaluation THAN
#  it is to use negative thick terms without intending to communicate the evaluation

h1 <- df %>% filter(prob == 0)
h1_V1 <- h1 %>% filter(item_step == 'V1')
#h1_V2 <- h1 %>% filter(item_step == 'V2')
#nrow(h1_V1)==nrow(df)/4

## are there outliers?
#outliers <- boxplot(h1_V1$value, plot=FALSE)$out
#outliers
# no outliers
## test ANOVA assumptions
# homogeneity of variances
```

```{r}
## homogeneity of variances
# pooled data
lawstat::levene.test(h1$value, h1$polarity, location = 'mean', trim.alpha=0.25, 
                     correction.method = 'correction.factor')
# first item subset
lawstat::levene.test(h1_V1$value, h1_V1$polarity, location = 'mean', trim.alpha=0.25, 
                     correction.method = 'correction.factor')
## global normality
# pooled data
shapiro.test(h1$value)
# first item subset
shapiro.test(h1_V1$value)
```

The one-sided t-test supports that the positive thick terms have a lower average agreement rating than negative thick terms, which indicates that it is more acceptable for positive thick terms to be used without intending to communicate the evaluation they usually. Thus, $H_1$ cannot be rejected for the first order subset.

```{r}
# testing h1 for first item subset
m1 <- aov(value ~ polarity, data = h1_V1)

t.test(h1_V1$value[h1_V1$polarity == 'positive'], 
       h1_V1$value[h1_V1$polarity == 'negative'], 
       alternative = 'less')
```
Next, we test for order effects in the pooled data. As can be seen in the ANOVA results, the order effects (`item_step`) are not significant on .05-alpha level. Thus, we proceeded to compute a one-sided t-test with $H_A:\mu_{pos}<\mu_{neg}$. As we can see $H_0$ has to be rejected in favour of $H_A$. This means that $H_1$ cannot be rejected for the pooled data.

```{r echo=T}
# are there order effects
m2 <- aov(value ~ polarity*item_step, data = h1)
summary(m2)
# order effects are not significant on 0.05-level

t.test(h1$value[h1$polarity == 'positive'], 
       h1$value[h1$polarity == 'negative'], 
       alternative = 'less')
```

## H2: How Problematic..

```{r include=F}
### H2
# It is more problematic to get a wrong impression of a person if the impression is wrongly negative, compared to when it is wrongly positive

h2 <- df %>% filter(prob == 1)
h2_V1 <- h2 %>% filter(item_step == 'V1')
#h1_V2 <- h1 %>% filter(item_step == 'V2')
nrow(h2_V1)==nrow(df)/4

## are there outliers?
outliers <- boxplot(h2_V1$value, plot=FALSE)$out
outliers
# yes there are outliers
```
For $H_2$, the homogenity of variance is not violated on a significance level of .01, neither for the pooled data (`h2`), nor the first item subset (`h2_V1`). We can use the same tests as above.

```{r}
# homogeneity of variances
lawstat::levene.test(h2$value, h2$polarity, location = 'mean', trim.alpha=0.25, 
                     correction.method = 'correction.factor')
lawstat::levene.test(h2_V1$value, h2_V1$polarity, location = 'mean', trim.alpha=0.25, 
                     correction.method = 'correction.factor')
# global normality
shapiro.test(h2$value)
shapiro.test(h2_V1$value)
```

The one-sided t-test shows that $H_0$ has to be rejected in favor of $H_A:\mu_{pos}<\mu_{neg}$. Thus, $H_2$ cannot be rejected for the first item subset.
```{r}
# testing
m1 <- aov(value ~ polarity, data = h2_V1)
summary(m1)

t.test(h1_V1$value[h1_V1$polarity == 'positive'], 
       h1_V1$value[h1_V1$polarity == 'negative'], 
       alternative = 'less')
```

Analogous to above, we tested for order effects, and they were also not significant on .05-alpha level. For the pooled data, $H_0$ also has to be rejected in favor of $H_A:\mu_{pos}<\mu_{neg}$. Thus $H_2$ cannot be rejected.
```{r}
# are there order effects
m2 <- aov(value ~ polarity*item_step, data = h1)
summary(m2)
# order effects are not significant on 0.05-level

t.test(h1$value[h1$polarity == 'positive'], 
       h1$value[h1$polarity == 'negative'], 
       alternative = 'less')
```

## Differences Between the Domains

We further explored domain differences in a 2x6x1 ANOVA. We computed both the estimated means and Tukey's HSD, which yield very similar results. As we can see, some of the within-domain differences are not significant.

```{r}
m3 <- aov(value ~ polarity*domain + item_step, data = h1)
summary(m3)
# estimated means
fittedMeans <- emmeans(m3, ~ polarity|domain)
# pairwise valence differences within domains
pairs(fittedMeans)
# valence contrasts within domains
contrast(fittedMeans)
```
```{r}
# Tukey's honestly significant difference
TukeyHSD(m3)
```
```{r}
TukeyHSD(m3, which = "domain")
TukeyHSD(m3, which = "polarity")
```
